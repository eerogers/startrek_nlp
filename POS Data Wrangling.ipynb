{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "\n",
    "nlp_sm = spacy.load('en_core_web_sm')\n",
    "nlp_md = spacy.load('en_core_web_md')\n",
    "\n",
    "deep_space = pd.read_csv('deep_space.csv')\n",
    "original = pd.read_csv('original.csv')\n",
    "enterprise = pd.read_csv('enterprise.csv')\n",
    "animated = pd.read_csv('animated.csv')\n",
    "next_gen = pd.read_csv('next_gen.csv')\n",
    "voyager = pd.read_csv('voyager.csv')\n",
    "\n",
    "#Original Series\n",
    "spock_lines = original[original['character'] == 'SPOCK']['lines']\n",
    "kirk_lines = original[original['character'] == 'KIRK']['lines']\n",
    "\n",
    "#Voyager\n",
    "janeway_lines = voyager[voyager['character'] == 'JANEWAY']['lines']\n",
    "#Enterprise\n",
    "archer_lines = enterprise[enterprise['character'] == 'ARCHER']['lines']\n",
    "#Deep Space 9\n",
    "sisko_lines = deep_space[deep_space['character'] == 'SISKO']['lines']\n",
    "\n",
    "#Next Generation\n",
    "picard_lines = next_gen[next_gen['character'] == 'PICARD']['lines']\n",
    "data_lines = next_gen[next_gen['character'] == 'DATA']['lines']\n",
    "\n",
    "#Animated Series\n",
    "spock_lines2 = animated[animated['character'] == 'SPOCK']['lines']\n",
    "kirk_lines2 = animated[animated['character'] == 'KIRK']['lines']\n",
    "\n",
    "spock_str = str([line for line in spock_lines])\n",
    "kirk_str = str([line for line in kirk_lines])\n",
    "janeway_str = str([line for line in janeway_lines])\n",
    "archer_str = str([line for line in archer_lines])\n",
    "sisko_str = str([line for line in sisko_lines])\n",
    "picard_str = str([line for line in picard_lines])\n",
    "data_str = str([line for line in data_lines])\n",
    "spock_str2 = str([line for line in spock_lines2])\n",
    "kirk_str2 = str([line for line in kirk_lines2])\n",
    "\n",
    "deep_space_lines = deep_space['lines']\n",
    "original_lines = original['lines']\n",
    "enterprise_lines = enterprise['lines']\n",
    "animated_lines = animated['lines']\n",
    "next_gen_lines = next_gen['lines']\n",
    "voyager_lines = voyager['lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[', 'PUNCT', 'punct'), ('\"', 'PUNCT', 'punct'), ('Check', 'VERB', 'ROOT'), ('the', 'DET', 'det'), ('circuit', 'NOUN', 'dobj'), ('.', 'PUNCT', 'punct'), ('It', 'PRON', 'nsubj'), ('ca', 'AUX', 'aux'), (\"n't\", 'PART', 'neg'), ('be', 'VERB', 'ROOT'), ('the', 'DET', 'det'), ('screen', 'NOUN', 'attr'), ('then', 'ADV', 'advmod'), ('.', 'PUNCT', 'punct'), ('Definitely', 'ADV', 'advmod'), ('something', 'PRON', 'nsubj'), ('out', 'ADV', 'advmod'), ('there', 'ADV', 'advmod'), (',', 'PUNCT', 'punct'), ('Captain', 'PROPN', 'appos'), (',', 'PUNCT', 'punct'), ('headed', 'VERB', 'ROOT'), ('this', 'DET', 'det'), ('way', 'NOUN', 'npadvmod'), ('.', 'PUNCT', 'punct'), ('Their', 'PRON', 'poss'), ('call', 'NOUN', 'compound'), ('letters', 'NOUN', 'nsubj'), ('check', 'VERB', 'ROOT'), ('with', 'ADP', 'prep'), ('a', 'DET', 'det'), ('survey', 'NOUN', 'compound'), ('expedition', 'NOUN', 'pobj'), ('.', 'PUNCT', 'punct'), ('SS', 'PROPN', 'compound'), ('Columbia', 'PROPN', 'ROOT'), ('.', 'PUNCT', 'punct'), ('It', 'PRON', 'nsubj'), ('disappeared', 'VERB', 'ROOT'), ('in', 'ADP', 'prep'), ('that', 'DET', 'det'), ('region', 'NOUN', 'pobj'), ('approximately', 'ADV', 'advmod'), ('eighteen', 'NUM', 'nummod'), ('years', 'NOUN', 'npadvmod'), ('ago', 'ADV', 'advmod'), ('.', 'PUNCT', 'punct'), ('Records', 'NOUN', 'nsubj'), ('show', 'VERB', 'ROOT'), ('the', 'DET', 'det'), ('Talos', 'PROPN', 'compound'), ('group', 'NOUN', 'nsubjpass'), ('has', 'AUX', 'aux'), ('never', 'ADV', 'neg'), ('been', 'AUX', 'auxpass'), ('explored', 'VERB', 'ccomp'), ('.', 'PUNCT', 'punct'), ('Solar', 'ADJ', 'amod'), ('system', 'NOUN', 'ROOT'), ('similar', 'ADJ', 'amod'), ('to', 'ADP', 'prep'), ('Earth', 'PROPN', 'pobj'), (',', 'PUNCT', 'punct'), ('eleven', 'NUM', 'nummod'), ('planets', 'NOUN', 'appos'), ('.', 'PUNCT', 'punct'), ('Number', 'NOUN', 'nsubj'), ('four', 'NUM', 'nummod'), ('seems', 'VERB', 'ROOT'), ('to', 'PART', 'aux'), ('be', 'VERB', 'xcomp'), ('Class', 'PROPN', 'compound'), ('M', 'PROPN', 'attr'), (',', 'PUNCT', 'punct'), ('oxygen', 'NOUN', 'compound'), ('atmosphere', 'NOUN', 'appos'), ('.', 'PUNCT', 'punct'), ('We', 'PRON', 'nsubj'), ('are', 'AUX', 'aux'), (\"n't\", 'PART', 'neg'), ('going', 'VERB', 'ROOT'), ('to', 'PART', 'aux'), ('go', 'VERB', 'xcomp'), (',', 'PUNCT', 'punct'), ('to', 'PART', 'aux'), ('be', 'VERB', 'xcomp'), ('certain', 'ADJ', 'acomp'), ('?', 'PUNCT', 'punct'), ('Mister', 'PROPN', 'compound'), ('Spock', 'PROPN', 'ROOT'), ('here', 'ADV', 'advmod'), ('.', 'PUNCT', 'punct'), ('We', 'PRON', 'nsubj'), (\"'re\", 'AUX', 'aux'), ('intercepting', 'VERB', 'ROOT'), ('a', 'DET', 'det'), ('follow', 'VERB', 'amod'), ('-', 'PUNCT', 'punct'), ('up', 'ADP', 'prt'), ('message', 'NOUN', 'dobj')]\n",
      "61526\n",
      "13.415466631992977\n",
      "25.42502356727237\n",
      "7.922382894574219\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "spock_pos = []\n",
    "spock_doc = nlp(spock_str)\n",
    "spock_verb = 0\n",
    "spock_noun = 0\n",
    "spock_q = 0\n",
    "spock_total = 0\n",
    "spock_sentences = 0\n",
    "for token in spock_doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    if token_pos == 'VERB':\n",
    "        spock_verb = spock_verb + 1\n",
    "    if token_pos == 'NOUN' or token_pos == 'PROPN':\n",
    "        spock_noun = spock_noun + 1\n",
    "    if token_text == '?':\n",
    "        spock_q = spock_q + 1\n",
    "    if token_text == '.' or token_text == '?' or token_text == \"!\":\n",
    "        spock_sentences = spock_sentences + 1\n",
    "    if token_pos != 'PUNCT':\n",
    "        spock_total = spock_total + 1\n",
    "    spock_pos.append((token_text, token_pos, token_dep))\n",
    "print(spock_pos[0:100])\n",
    "print(spock_total)\n",
    "print(spock_verb/spock_total * 100)\n",
    "print(spock_noun/spock_total * 100)\n",
    "print(spock_q/spock_sentences * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[', 'PUNCT', 'punct'), ('\"', 'PUNCT', 'punct'), ('Shall', 'AUX', 'aux'), ('we', 'PRON', 'nsubj'), ('pick', 'VERB', 'ROOT'), ('some', 'DET', 'det'), ('flowers', 'NOUN', 'dobj'), (',', 'PUNCT', 'punct'), ('Doctor', 'PROPN', 'npadvmod'), ('?', 'PUNCT', 'punct'), ('When', 'ADV', 'advmod'), ('a', 'DET', 'det'), ('man', 'NOUN', 'nsubj'), ('visits', 'VERB', 'ROOT'), ('an', 'DET', 'det'), ('old', 'ADJ', 'amod'), ('girlfriend', 'NOUN', 'dobj'), ('she', 'PRON', 'nsubj'), ('usually', 'ADV', 'advmod'), ('expects', 'VERB', 'relcl'), ('something', 'PRON', 'dobj'), ('like', 'ADP', 'prep'), ('that', 'DET', 'pobj'), ('.', 'PUNCT', 'punct'), ('They', 'PRON', 'nsubj'), (\"'ll\", 'AUX', 'aux'), ('be', 'VERB', 'ROOT'), ('along', 'ADV', 'advmod'), ('.', 'PUNCT', 'punct'), ('You', 'PRON', 'nsubj'), ('rushed', 'VERB', 'ROOT'), ('us', 'PRON', 'dobj'), ('down', 'ADV', 'advmod'), ('ten', 'NUM', 'nummod'), ('minutes', 'NOUN', 'npadvmod'), ('early', 'ADV', 'advmod'), ('.', 'PUNCT', 'punct'), ('Professor', 'PROPN', 'compound'), ('Crater', 'PROPN', 'ROOT'), ('?', 'PUNCT', 'punct'), ('Professor', 'PROPN', 'ROOT'), ('?', 'PUNCT', 'punct'), ('Mrs.', 'PROPN', 'compound'), ('Crater', 'PROPN', 'ROOT'), ('?', 'PUNCT', 'punct'), ('Nervous', 'ADJ', 'ROOT'), (',', 'PUNCT', 'punct'), ('Dr.', 'PROPN', 'compound'), ('McCoy', 'PROPN', 'appos'), ('?', 'PUNCT', 'punct'), ('Mrs.', 'PROPN', 'compound'), ('Crater', 'PROPN', 'ROOT'), ('.', 'PUNCT', 'punct'), ('I', 'PRON', 'nsubj'), (\"'ve\", 'AUX', 'aux'), ('heard', 'VERB', 'ROOT'), ('a', 'DET', 'det'), ('great', 'ADJ', 'amod'), ('deal', 'NOUN', 'dobj'), ('about', 'ADP', 'prep'), ('you', 'PRON', 'pobj'), ('.', 'PUNCT', 'punct'), ('Something', 'PRON', 'ROOT'), ('wrong', 'ADJ', 'amod'), (',', 'PUNCT', 'punct'), ('Darnell', 'PROPN', 'appos'), ('?', 'PUNCT', 'punct'), ('Why', 'ADV', 'advmod'), ('do', 'AUX', 'aux'), (\"n't\", 'PART', 'neg'), ('you', 'PRON', 'nsubj'), ('step', 'VERB', 'ROOT'), ('outside', 'ADV', 'advmod'), (',', 'PUNCT', 'punct'), ('Darnell', 'PROPN', 'npadvmod'), ('.', 'PUNCT', 'punct'), ('Maybe', 'ADV', 'advmod'), ('I', 'PRON', 'nsubj'), (\"'ll\", 'AUX', 'aux'), ('step', 'VERB', 'ROOT'), ('outside', 'ADV', 'advmod'), (',', 'PUNCT', 'punct'), ('too', 'ADV', 'advmod'), ('.', 'PUNCT', 'punct'), ('Plum', 'PROPN', 'ROOT'), ('?', 'PUNCT', 'punct'), ('Professor', 'PROPN', 'compound'), ('Crater', 'PROPN', 'npadvmod'), (',', 'PUNCT', 'punct'), ('I', 'PRON', 'nsubj'), (\"'m\", 'VERB', 'ROOT'), ('Captain', 'PROPN', 'compound'), ('Kirk', 'PROPN', 'attr'), ('.', 'PUNCT', 'punct'), ('This', 'DET', 'nsubj'), ('is', 'AUX', 'ROOT'), ('Quote', 'PROPN', 'attr'), ('.', 'PUNCT', 'punct'), ('All', 'DET', 'det'), ('research', 'NOUN', 'compound')]\n",
      "109394\n",
      "15.514562041793884\n",
      "23.255388778177963\n",
      "18.711602597858523\n"
     ]
    }
   ],
   "source": [
    "kirk_pos = []\n",
    "kirk_doc = nlp(kirk_str)\n",
    "kirk_verb = 0\n",
    "kirk_noun = 0\n",
    "kirk_q = 0\n",
    "kirk_total = 0\n",
    "kirk_sentences = 0\n",
    "for token in kirk_doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    if token_pos == 'VERB':\n",
    "        kirk_verb = kirk_verb + 1\n",
    "    if token_pos == 'NOUN' or token_pos == 'PROPN':\n",
    "        kirk_noun = kirk_noun + 1\n",
    "    if token_text == '?':\n",
    "        kirk_q = kirk_q + 1\n",
    "    if token_text == '.' or token_text == '?' or token_text == \"!\":\n",
    "        kirk_sentences = kirk_sentences + 1\n",
    "    if token_pos != 'PUNCT':\n",
    "        kirk_total = kirk_total + 1\n",
    "    kirk_pos.append((token_text, token_pos, token_dep))\n",
    "print(kirk_pos[0:100])\n",
    "print(kirk_total)\n",
    "print(kirk_verb/kirk_total * 100)\n",
    "print(kirk_noun/kirk_total * 100)\n",
    "print(kirk_q/kirk_sentences * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[', 'PUNCT', 'punct'), ('\"', 'PUNCT', 'punct'), ('I', 'PRON', 'nsubj'), ('can', 'AUX', 'aux'), ('only', 'ADV', 'advmod'), ('describe', 'VERB', 'ROOT'), ('it', 'PRON', 'dobj'), ('as', 'ADP', 'prep'), ('hypergravity', 'NOUN', 'pobj'), (',', 'PUNCT', 'punct'), ('Captain', 'PROPN', 'conj'), (',', 'PUNCT', 'punct'), ('more', 'ADV', 'advmod'), ('powerful', 'ADJ', 'amod'), ('than', 'SCONJ', 'prep'), ('any', 'DET', 'pobj'), ('we', 'PRON', 'nsubj'), (\"'ve\", 'AUX', 'aux'), ('ever', 'ADV', 'advmod'), ('encountered', 'VERB', 'relcl'), ('.', 'PUNCT', 'punct'), ('It', 'PRON', 'nsubj'), (\"'s\", 'AUX', 'aux'), ('dragging', 'VERB', 'ROOT'), ('the', 'DET', 'det'), ('Enterprise', 'NOUN', 'dobj'), ('toward', 'ADP', 'prep'), ('it', 'PRON', 'pobj'), ('.', 'PUNCT', 'punct'), ('Negative', 'ADJ', 'amod'), ('star', 'NOUN', 'compound'), ('mass', 'NOUN', 'ROOT'), ('.', 'PUNCT', 'punct'), ('Spectra', 'PROPN', 'compound'), ('analysis', 'NOUN', 'nsubj'), (',', 'PUNCT', 'punct'), ('imploded', 'VERB', 'amod'), ('matter', 'NOUN', 'appos'), (',', 'PUNCT', 'punct'), ('but', 'CCONJ', 'cc'), ('every', 'DET', 'det'), ('reading', 'NOUN', 'nsubj'), ('on', 'ADP', 'prep'), ('it', 'PRON', 'pobj'), ('is', 'AUX', 'ROOT'), ('negative', 'ADJ', 'acomp'), ('.', 'PUNCT', 'punct'), ('Impact', 'NOUN', 'ROOT'), ('in', 'ADP', 'prep'), ('ninety', 'NUM', 'compound'), ('three', 'NUM', 'nummod'), ('seconds', 'NOUN', 'pobj'), ('.', 'PUNCT', 'punct'), ('Ninety', 'NUM', 'ROOT'), ('two', 'NUM', 'nummod'), ('.', 'PUNCT', 'punct'), ('Ninety', 'NUM', 'nummod'), ('one', 'NUM', 'ROOT'), ('.', 'PUNCT', 'punct'), ('Forty', 'NUM', 'nummod'), ('seconds', 'NOUN', 'ROOT'), (',', 'PUNCT', 'punct'), ('Captain', 'PROPN', 'npadvmod'), ('.', 'PUNCT', 'punct'), ('Thirty', 'NUM', 'compound'), ('nine', 'NUM', 'ROOT'), (',', 'PUNCT', 'punct'), ('thirty', 'NUM', 'compound'), ('eight', 'NUM', 'appos'), ('.', 'PUNCT', 'punct'), ('Nine', 'NUM', 'nummod'), ('seconds', 'NOUN', 'ROOT'), ('.', 'PUNCT', 'punct'), ('Eight', 'NUM', 'ROOT'), (',', 'PUNCT', 'punct'), ('seven', 'NUM', 'appos'), ('.', 'PUNCT', 'punct'), ('Orbital', 'ADJ', 'amod'), ('velocity', 'NOUN', 'ROOT'), ('.', 'PUNCT', 'punct'), ('I', 'PRON', 'nsubj'), (\"'ll\", 'AUX', 'aux'), ('need', 'VERB', 'ROOT'), ('some', 'DET', 'det'), ('time', 'NOUN', 'dobj'), ('for', 'ADP', 'prep'), ('the', 'DET', 'det'), ('computations', 'NOUN', 'pobj'), (',', 'PUNCT', 'punct'), ('Captain', 'PROPN', 'appos'), ('.', 'PUNCT', 'punct'), ('Confirmed', 'PROPN', 'ROOT'), (',', 'PUNCT', 'punct'), ('Captain', 'PROPN', 'conj'), (',', 'PUNCT', 'punct'), ('but', 'CCONJ', 'cc'), ('it', 'PRON', 'nsubj'), ('is', 'VERB', 'conj'), (\"n't\", 'PART', 'neg'), ('possible', 'ADJ', 'acomp')]\n",
      "11985\n",
      "12.807676261994159\n",
      "26.157697121401753\n",
      "6.085192697768763\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "spock_pos2 = []\n",
    "spock_doc2 = nlp(spock_str2)\n",
    "spock_verb2 = 0\n",
    "spock_noun2 = 0\n",
    "spock_q2 = 0\n",
    "spock_total2 = 0\n",
    "spock_sentences2 = 0\n",
    "for token in spock_doc2:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    if token_pos == 'VERB':\n",
    "        spock_verb2 = spock_verb2 + 1\n",
    "    if token_pos == 'NOUN' or token_pos == 'PROPN':\n",
    "        spock_noun2 = spock_noun2 + 1\n",
    "    if token_text == '?':\n",
    "        spock_q2 = spock_q2 + 1\n",
    "    if token_text == '.' or token_text == '?' or token_text == \"!\":\n",
    "        spock_sentences2 = spock_sentences2 + 1\n",
    "    if token_pos != 'PUNCT':\n",
    "        spock_total2 = spock_total2 + 1\n",
    "    spock_pos2.append((token_text, token_pos, token_dep))\n",
    "print(spock_pos2[0:100])\n",
    "print(spock_total2)\n",
    "print(spock_verb2/spock_total2 * 100)\n",
    "print(spock_noun2/spock_total2 * 100)\n",
    "print(spock_q2/spock_sentences2 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[', 'PUNCT', 'punct'), ('\"', 'PUNCT', 'punct'), ('Situation', 'PROPN', 'ROOT'), (',', 'PUNCT', 'punct'), ('Mister', 'PROPN', 'compound'), ('Scott', 'PROPN', 'appos'), ('?', 'PUNCT', 'punct'), ('Mister', 'PROPN', 'compound'), ('Sulu', 'PROPN', 'ROOT'), ('?', 'PUNCT', 'punct'), ('Stand', 'VERB', 'ROOT'), ('by', 'ADP', 'prt'), ('to', 'PART', 'aux'), ('reverse', 'VERB', 'advcl'), ('course', 'NOUN', 'dobj'), ('.', 'PUNCT', 'punct'), ('Reverse', 'VERB', 'amod'), ('course', 'NOUN', 'ROOT'), ('.', 'PUNCT', 'punct'), ('Why', 'ADV', 'advmod'), ('are', 'AUX', 'aux'), (\"n't\", 'PART', 'neg'), ('our', 'PRON', 'poss'), ('sensors', 'NOUN', 'nsubj'), ('picking', 'VERB', 'ROOT'), ('it', 'PRON', 'dobj'), ('up', 'ADP', 'prt'), ('?', 'PUNCT', 'punct'), ('Forward', 'ADJ', 'amod'), ('scanners', 'NOUN', 'ROOT'), (',', 'PUNCT', 'punct'), ('Mister', 'PROPN', 'compound'), ('Sulu', 'PROPN', 'appos'), ('.', 'PUNCT', 'punct'), ('Full', 'ADJ', 'amod'), ('reverse', 'ADJ', 'amod'), ('thrust', 'NOUN', 'ROOT'), ('.', 'PUNCT', 'punct'), ('How', 'ADV', 'advmod'), ('much', 'ADJ', 'amod'), ('time', 'NOUN', 'dobj'), ('do', 'AUX', 'aux'), ('we', 'PRON', 'nsubj'), ('have', 'VERB', 'ROOT'), ('?', 'PUNCT', 'punct'), ('Sulu', 'PROPN', 'dep'), (',', 'PUNCT', 'punct'), ('flank', 'NOUN', 'compound'), ('speed', 'NOUN', 'ROOT'), ('ahead', 'ADV', 'advmod'), ('.', 'PUNCT', 'punct'), ('Our', 'PRON', 'poss'), ('only', 'ADJ', 'amod'), ('chance', 'NOUN', 'nsubj'), ('is', 'AUX', 'ROOT'), ('to', 'PART', 'aux'), ('try', 'VERB', 'xcomp'), ('to', 'PART', 'aux'), ('get', 'VERB', 'xcomp'), ('into', 'ADP', 'prep'), ('orbit', 'NOUN', 'pobj'), ('around', 'ADP', 'prep'), ('that', 'DET', 'det'), ('thing', 'NOUN', 'pobj'), ('.', 'PUNCT', 'punct'), ('Steady', 'ADJ', 'ROOT'), ('as', 'ADP', 'mark'), ('she', 'PRON', 'nsubj'), ('goes', 'VERB', 'advcl'), (',', 'PUNCT', 'punct'), ('Mister', 'PROPN', 'compound'), ('Sulu', 'PROPN', 'npadvmod'), ('.', 'PUNCT', 'punct'), ('Maintain', 'VERB', 'ROOT'), ('orbit', 'NOUN', 'dobj'), ('.', 'PUNCT', 'punct'), ('Slingshot', 'PROPN', 'compound'), ('effect', 'NOUN', 'dep'), (',', 'PUNCT', 'punct'), ('Mister', 'PROPN', 'compound'), ('Spock', 'PROPN', 'ROOT'), ('?', 'PUNCT', 'punct'), ('Do', 'AUX', 'aux'), ('we', 'PRON', 'nsubj'), ('have', 'VERB', 'ROOT'), ('enough', 'ADJ', 'amod'), ('power', 'NOUN', 'dobj'), ('?', 'PUNCT', 'punct'), ('Put', 'VERB', 'ROOT'), ('us', 'PRON', 'dobj'), ('alongside', 'ADV', 'prt'), (',', 'PUNCT', 'punct'), ('Mister', 'PROPN', 'compound'), ('Sulu', 'PROPN', 'npadvmod'), ('.', 'PUNCT', 'punct'), ('It', 'PRON', 'nsubjpass'), (\"'s\", 'AUX', 'auxpass'), ('been', 'AUX', 'auxpass'), ('damaged', 'VERB', 'ROOT'), ('.', 'PUNCT', 'punct')]\n",
      "15523\n",
      "15.351414030793018\n",
      "25.47188043548283\n",
      "18.72759856630824\n"
     ]
    }
   ],
   "source": [
    "kirk_pos2 = []\n",
    "kirk_doc2 = nlp(kirk_str2)\n",
    "kirk_verb2 = 0\n",
    "kirk_noun2 = 0\n",
    "kirk_q2 = 0\n",
    "kirk_total2 = 0\n",
    "kirk_sentences2 = 0\n",
    "for token in kirk_doc2:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    if token_pos == 'VERB':\n",
    "        kirk_verb2 = kirk_verb2 + 1\n",
    "    if token_pos == 'NOUN' or token_pos == 'PROPN':\n",
    "        kirk_noun2 = kirk_noun2 + 1\n",
    "    if token_text == '?':\n",
    "        kirk_q2 = kirk_q2 + 1\n",
    "    if token_text == '.' or token_text == '?' or token_text == \"!\":\n",
    "        kirk_sentences2 = kirk_sentences2 + 1\n",
    "    if token_pos != 'PUNCT':\n",
    "        kirk_total2 = kirk_total2 + 1\n",
    "    kirk_pos2.append((token_text, token_pos, token_dep))\n",
    "print(kirk_pos2[0:100])\n",
    "print(kirk_total2)\n",
    "print(kirk_verb2/kirk_total2 * 100)\n",
    "print(kirk_noun2/kirk_total2 * 100)\n",
    "print(kirk_q2/kirk_sentences2 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRAZY that it's about the same proportion for kirk and spock's parts of speech between animated and original series.\n",
    "#Loop to create an object containing this information for all characters (within the scope)\n",
    "str_loop = [(\"spock1\", spock_str), (\"kirk1\", kirk_str), (\"janeway\", janeway_str), (\"archer\", archer_str), \n",
    "            (\"sisko\", sisko_str), (\"picard\", picard_str), (\"data\", data_str), (\"spock2\", spock_str2), \n",
    "            (\"kirk2\", kirk_str2)]\n",
    "\n",
    "char_pos_nums = []\n",
    "\n",
    "char_pos = []\n",
    "for char, strings in str_loop:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    char_doc = nlp(strings)\n",
    "    char_verb = 0\n",
    "    char_noun = 0\n",
    "    char_adj = 0\n",
    "    char_adv = 0\n",
    "    char_q = 0\n",
    "    char_total = 0\n",
    "    char_sentences = 0\n",
    "    for token in char_doc:\n",
    "        token_text = token.text\n",
    "        token_pos = token.pos_\n",
    "        token_dep = token.dep_\n",
    "        if token_pos == 'VERB':\n",
    "            char_verb = char_verb + 1\n",
    "        if token_pos == 'ADV':\n",
    "            char_adv = char_adv + 1\n",
    "        if token_pos == 'ADJ':\n",
    "            char_adj = char_adj + 1\n",
    "        if token_pos == 'NOUN' or token_pos == 'PROPN':\n",
    "            char_noun = char_noun + 1\n",
    "        if token_text == '?':\n",
    "            char_q = char_q + 1\n",
    "        if token_text == '.' or token_text == '?' or token_text == \"!\":\n",
    "            char_sentences = char_sentences + 1\n",
    "        if token_pos != 'PUNCT':\n",
    "            char_total = char_total + 1\n",
    "        char_pos.append((char,[token_text, token_pos, token_dep]))\n",
    "    char_pos_nums.append((char, char_verb, char_verb/char_total * 100, char_noun, char_noun/char_total * 100, char_adj, char_adj/char_total * 100, char_adv, char_adv/char_total * 100, char_q/char_sentences * 100, char_total, char_sentences))\n",
    "#print(kirk_pos2[0:100])\n",
    "#print(kirk_total2)\n",
    "#print(kirk_verb2/kirk_total2 * 100)\n",
    "#print(kirk_noun2/kirk_total2 * 100)\n",
    "#print(kirk_q2/kirk_sentences2 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spock1', 8254, 13.415466631992977, 15643, 25.42502356727237, 4555, 7.4033741832721125, 3886, 6.316028995871664, 7.922382894574219, 61526, 8091), ('kirk1', 16972, 15.514562041793884, 25440, 23.255388778177963, 5531, 5.056035980035468, 6379, 5.831215605974734, 18.711602597858523, 109394, 17091), ('janeway', 23897, 17.158140369772035, 30159, 21.65428109854604, 7651, 5.493448213965177, 7947, 5.705977382875606, 16.81766704416761, 139275, 19426), ('archer', 16460, 18.068057080131723, 17279, 18.967069154774975, 4517, 4.958287596048298, 5790, 6.355653128430297, 20.124512451245124, 91100, 13332), ('sisko', 17597, 17.053504801961488, 20736, 20.095554672584726, 5273, 5.1101398431973015, 6623, 6.41844418386037, 18.364707572927145, 103187, 13918), ('picard', 23047, 15.416775367408508, 35977, 24.066009779722126, 8184, 5.474503822921474, 8748, 5.8517790130641565, 19.382316550870847, 149493, 21014), ('data', 11094, 13.742103307320699, 22258, 27.570915397002356, 6032, 7.471819645732689, 3721, 4.609191130930261, 8.592592592592592, 80730, 10125), ('spock2', 1535, 12.807676261994159, 3135, 26.157697121401753, 941, 7.851481017939091, 688, 5.740508969545265, 6.085192697768763, 11985, 1479), ('kirk2', 2383, 15.351414030793018, 3954, 25.47188043548283, 821, 5.2889261096437545, 891, 5.73986987051472, 18.72759856630824, 15523, 2232)]\n"
     ]
    }
   ],
   "source": [
    "print(char_pos_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('spock1', ['[', 'PUNCT', 'punct']), ('spock1', ['\"', 'PUNCT', 'punct']), ('spock1', ['Check', 'VERB', 'ROOT']), ('spock1', ['the', 'DET', 'det']), ('spock1', ['circuit', 'NOUN', 'dobj']), ('spock1', ['.', 'PUNCT', 'punct']), ('spock1', ['It', 'PRON', 'nsubj']), ('spock1', ['ca', 'AUX', 'aux']), ('spock1', [\"n't\", 'PART', 'neg']), ('spock1', ['be', 'VERB', 'ROOT']), ('spock1', ['the', 'DET', 'det']), ('spock1', ['screen', 'NOUN', 'attr']), ('spock1', ['then', 'ADV', 'advmod']), ('spock1', ['.', 'PUNCT', 'punct']), ('spock1', ['Definitely', 'ADV', 'advmod']), ('spock1', ['something', 'PRON', 'nsubj']), ('spock1', ['out', 'ADV', 'advmod']), ('spock1', ['there', 'ADV', 'advmod']), ('spock1', [',', 'PUNCT', 'punct']), ('spock1', ['Captain', 'PROPN', 'appos']), ('spock1', [',', 'PUNCT', 'punct']), ('spock1', ['headed', 'VERB', 'ROOT']), ('spock1', ['this', 'DET', 'det']), ('spock1', ['way', 'NOUN', 'npadvmod']), ('spock1', ['.', 'PUNCT', 'punct']), ('spock1', ['Their', 'PRON', 'poss']), ('spock1', ['call', 'NOUN', 'compound']), ('spock1', ['letters', 'NOUN', 'nsubj']), ('spock1', ['check', 'VERB', 'ROOT']), ('spock1', ['with', 'ADP', 'prep']), ('spock1', ['a', 'DET', 'det']), ('spock1', ['survey', 'NOUN', 'compound']), ('spock1', ['expedition', 'NOUN', 'pobj']), ('spock1', ['.', 'PUNCT', 'punct']), ('spock1', ['SS', 'PROPN', 'compound']), ('spock1', ['Columbia', 'PROPN', 'ROOT']), ('spock1', ['.', 'PUNCT', 'punct']), ('spock1', ['It', 'PRON', 'nsubj']), ('spock1', ['disappeared', 'VERB', 'ROOT']), ('spock1', ['in', 'ADP', 'prep']), ('spock1', ['that', 'DET', 'det']), ('spock1', ['region', 'NOUN', 'pobj']), ('spock1', ['approximately', 'ADV', 'advmod']), ('spock1', ['eighteen', 'NUM', 'nummod']), ('spock1', ['years', 'NOUN', 'npadvmod']), ('spock1', ['ago', 'ADV', 'advmod']), ('spock1', ['.', 'PUNCT', 'punct']), ('spock1', ['Records', 'NOUN', 'nsubj']), ('spock1', ['show', 'VERB', 'ROOT']), ('spock1', ['the', 'DET', 'det']), ('spock1', ['Talos', 'PROPN', 'compound']), ('spock1', ['group', 'NOUN', 'nsubjpass']), ('spock1', ['has', 'AUX', 'aux']), ('spock1', ['never', 'ADV', 'neg']), ('spock1', ['been', 'AUX', 'auxpass']), ('spock1', ['explored', 'VERB', 'ccomp']), ('spock1', ['.', 'PUNCT', 'punct']), ('spock1', ['Solar', 'ADJ', 'amod']), ('spock1', ['system', 'NOUN', 'ROOT']), ('spock1', ['similar', 'ADJ', 'amod']), ('spock1', ['to', 'ADP', 'prep']), ('spock1', ['Earth', 'PROPN', 'pobj']), ('spock1', [',', 'PUNCT', 'punct']), ('spock1', ['eleven', 'NUM', 'nummod']), ('spock1', ['planets', 'NOUN', 'appos']), ('spock1', ['.', 'PUNCT', 'punct']), ('spock1', ['Number', 'NOUN', 'nsubj']), ('spock1', ['four', 'NUM', 'nummod']), ('spock1', ['seems', 'VERB', 'ROOT']), ('spock1', ['to', 'PART', 'aux']), ('spock1', ['be', 'VERB', 'xcomp']), ('spock1', ['Class', 'PROPN', 'compound']), ('spock1', ['M', 'PROPN', 'attr']), ('spock1', [',', 'PUNCT', 'punct']), ('spock1', ['oxygen', 'NOUN', 'compound']), ('spock1', ['atmosphere', 'NOUN', 'appos']), ('spock1', ['.', 'PUNCT', 'punct']), ('spock1', ['We', 'PRON', 'nsubj']), ('spock1', ['are', 'AUX', 'aux']), ('spock1', [\"n't\", 'PART', 'neg']), ('spock1', ['going', 'VERB', 'ROOT']), ('spock1', ['to', 'PART', 'aux']), ('spock1', ['go', 'VERB', 'xcomp']), ('spock1', [',', 'PUNCT', 'punct']), ('spock1', ['to', 'PART', 'aux']), ('spock1', ['be', 'VERB', 'xcomp']), ('spock1', ['certain', 'ADJ', 'acomp']), ('spock1', ['?', 'PUNCT', 'punct']), ('spock1', ['Mister', 'PROPN', 'compound']), ('spock1', ['Spock', 'PROPN', 'ROOT']), ('spock1', ['here', 'ADV', 'advmod']), ('spock1', ['.', 'PUNCT', 'punct']), ('spock1', ['We', 'PRON', 'nsubj']), ('spock1', [\"'re\", 'AUX', 'aux']), ('spock1', ['intercepting', 'VERB', 'ROOT']), ('spock1', ['a', 'DET', 'det']), ('spock1', ['follow', 'VERB', 'amod']), ('spock1', ['-', 'PUNCT', 'punct']), ('spock1', ['up', 'ADP', 'prt']), ('spock1', ['message', 'NOUN', 'dobj'])]\n"
     ]
    }
   ],
   "source": [
    "print(char_pos[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#char, char_verb, char_verb/char_total * 100, char_noun, char_noun/char_total * 100, char_adj, char_adj/char_total * 100, char_adv, char_adv/char_total * 100, char_q/char_sentences * 100, char_total, char_sentences\n",
    "character_pos_prcts = pd.DataFrame(char_pos_nums, columns=['character', 'verbs','verb_prct', 'nouns', 'noun_prct', 'adjs', 'adj_prct', 'advs', 'adv_prct', 'question_prct', 'total_words', 'total_sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>verbs</th>\n",
       "      <th>verb_prct</th>\n",
       "      <th>nouns</th>\n",
       "      <th>noun_prct</th>\n",
       "      <th>adjs</th>\n",
       "      <th>adj_prct</th>\n",
       "      <th>advs</th>\n",
       "      <th>adv_prct</th>\n",
       "      <th>question_prct</th>\n",
       "      <th>total_words</th>\n",
       "      <th>total_sentences</th>\n",
       "      <th>avg_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spock1</td>\n",
       "      <td>8254</td>\n",
       "      <td>13.415467</td>\n",
       "      <td>15643</td>\n",
       "      <td>25.425024</td>\n",
       "      <td>4555</td>\n",
       "      <td>7.403374</td>\n",
       "      <td>3886</td>\n",
       "      <td>6.316029</td>\n",
       "      <td>7.922383</td>\n",
       "      <td>61526</td>\n",
       "      <td>8091</td>\n",
       "      <td>7.604252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kirk1</td>\n",
       "      <td>16972</td>\n",
       "      <td>15.514562</td>\n",
       "      <td>25440</td>\n",
       "      <td>23.255389</td>\n",
       "      <td>5531</td>\n",
       "      <td>5.056036</td>\n",
       "      <td>6379</td>\n",
       "      <td>5.831216</td>\n",
       "      <td>18.711603</td>\n",
       "      <td>109394</td>\n",
       "      <td>17091</td>\n",
       "      <td>6.400679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>janeway</td>\n",
       "      <td>23897</td>\n",
       "      <td>17.158140</td>\n",
       "      <td>30159</td>\n",
       "      <td>21.654281</td>\n",
       "      <td>7651</td>\n",
       "      <td>5.493448</td>\n",
       "      <td>7947</td>\n",
       "      <td>5.705977</td>\n",
       "      <td>16.817667</td>\n",
       "      <td>139275</td>\n",
       "      <td>19426</td>\n",
       "      <td>7.169515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>archer</td>\n",
       "      <td>16460</td>\n",
       "      <td>18.068057</td>\n",
       "      <td>17279</td>\n",
       "      <td>18.967069</td>\n",
       "      <td>4517</td>\n",
       "      <td>4.958288</td>\n",
       "      <td>5790</td>\n",
       "      <td>6.355653</td>\n",
       "      <td>20.124512</td>\n",
       "      <td>91100</td>\n",
       "      <td>13332</td>\n",
       "      <td>6.833183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sisko</td>\n",
       "      <td>17597</td>\n",
       "      <td>17.053505</td>\n",
       "      <td>20736</td>\n",
       "      <td>20.095555</td>\n",
       "      <td>5273</td>\n",
       "      <td>5.110140</td>\n",
       "      <td>6623</td>\n",
       "      <td>6.418444</td>\n",
       "      <td>18.364708</td>\n",
       "      <td>103187</td>\n",
       "      <td>13918</td>\n",
       "      <td>7.413924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>picard</td>\n",
       "      <td>23047</td>\n",
       "      <td>15.416775</td>\n",
       "      <td>35977</td>\n",
       "      <td>24.066010</td>\n",
       "      <td>8184</td>\n",
       "      <td>5.474504</td>\n",
       "      <td>8748</td>\n",
       "      <td>5.851779</td>\n",
       "      <td>19.382317</td>\n",
       "      <td>149493</td>\n",
       "      <td>21014</td>\n",
       "      <td>7.113972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data</td>\n",
       "      <td>11094</td>\n",
       "      <td>13.742103</td>\n",
       "      <td>22258</td>\n",
       "      <td>27.570915</td>\n",
       "      <td>6032</td>\n",
       "      <td>7.471820</td>\n",
       "      <td>3721</td>\n",
       "      <td>4.609191</td>\n",
       "      <td>8.592593</td>\n",
       "      <td>80730</td>\n",
       "      <td>10125</td>\n",
       "      <td>7.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spock2</td>\n",
       "      <td>1535</td>\n",
       "      <td>12.807676</td>\n",
       "      <td>3135</td>\n",
       "      <td>26.157697</td>\n",
       "      <td>941</td>\n",
       "      <td>7.851481</td>\n",
       "      <td>688</td>\n",
       "      <td>5.740509</td>\n",
       "      <td>6.085193</td>\n",
       "      <td>11985</td>\n",
       "      <td>1479</td>\n",
       "      <td>8.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kirk2</td>\n",
       "      <td>2383</td>\n",
       "      <td>15.351414</td>\n",
       "      <td>3954</td>\n",
       "      <td>25.471880</td>\n",
       "      <td>821</td>\n",
       "      <td>5.288926</td>\n",
       "      <td>891</td>\n",
       "      <td>5.739870</td>\n",
       "      <td>18.727599</td>\n",
       "      <td>15523</td>\n",
       "      <td>2232</td>\n",
       "      <td>6.954749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  character  verbs  verb_prct  nouns  noun_prct  adjs  adj_prct  advs  \\\n",
       "0    spock1   8254  13.415467  15643  25.425024  4555  7.403374  3886   \n",
       "1     kirk1  16972  15.514562  25440  23.255389  5531  5.056036  6379   \n",
       "2   janeway  23897  17.158140  30159  21.654281  7651  5.493448  7947   \n",
       "3    archer  16460  18.068057  17279  18.967069  4517  4.958288  5790   \n",
       "4     sisko  17597  17.053505  20736  20.095555  5273  5.110140  6623   \n",
       "5    picard  23047  15.416775  35977  24.066010  8184  5.474504  8748   \n",
       "6      data  11094  13.742103  22258  27.570915  6032  7.471820  3721   \n",
       "7    spock2   1535  12.807676   3135  26.157697   941  7.851481   688   \n",
       "8     kirk2   2383  15.351414   3954  25.471880   821  5.288926   891   \n",
       "\n",
       "   adv_prct  question_prct  total_words  total_sentences  avg_sentence  \n",
       "0  6.316029       7.922383        61526             8091      7.604252  \n",
       "1  5.831216      18.711603       109394            17091      6.400679  \n",
       "2  5.705977      16.817667       139275            19426      7.169515  \n",
       "3  6.355653      20.124512        91100            13332      6.833183  \n",
       "4  6.418444      18.364708       103187            13918      7.413924  \n",
       "5  5.851779      19.382317       149493            21014      7.113972  \n",
       "6  4.609191       8.592593        80730            10125      7.973333  \n",
       "7  5.740509       6.085193        11985             1479      8.103448  \n",
       "8  5.739870      18.727599        15523             2232      6.954749  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_pos_prcts['avg_sentence'] = character_pos_prcts['total_words']/character_pos_prcts['total_sentences']\n",
    "character_pos_prcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_pos_prcts.to_csv('char_pos_prcts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
